{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team 3 - Merchant Category Recommendation\n",
    "## XGBoost Model Parameter Tuning and Training\n",
    "\n",
    "### Team 3\n",
    "- Vinicio De Sola\n",
    "- Kevin Hanna\n",
    "- Pri Nonis\n",
    "- Bradley Nott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import pandas              as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics       import mean_squared_error\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load engineered (expanded) training data\n",
    "#train = pd.read_pickle('./Elo_kaggle/input/engineered_train.pkl')\n",
    "train = pd.read_pickle('./Elo_kaggle/input/engineered_train_new.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE is 14.41\n"
     ]
    }
   ],
   "source": [
    "# Simple (baseline) linear regression model RMSE: 15.059\n",
    "# - mean of training target: -0.392\n",
    "# - mean of testing target: -0.399\n",
    "\n",
    "# Create baseline with expanded data set\n",
    "\n",
    "# Extract features and target\n",
    "X, y = train.iloc[:,1:].values, train.iloc[:,0].values\n",
    "\n",
    "# Create a train/test split for a single baseline model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2)\n",
    "\n",
    "# Convert to XGBoost DMatrices\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Training mean\n",
    "mean_train = np.mean(y_train)\n",
    "\n",
    "# Use mean value to make baseline predictions on the test set\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_baseline = mean_squared_error(y_test, baseline_predictions)\n",
    "print(\"Baseline RMSE is {:.2f}\".format(rmse_baseline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use some default parameters for a baseline XGBoost model\n",
    "params = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective':'reg:linear',\n",
    "}\n",
    "\n",
    "# num_boost_round: number of boosting rounds/trees/estimators to build (1 = a single decision tree)\n",
    "# - XGBoost has a method to find optimal number of rounds while training\n",
    "# - early_stopping_round stops training if performance has not increased for n boosting rounds\n",
    "\n",
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:3.76525\n",
      "Will train until Test-rmse hasn't improved in 10 rounds.\n",
      "[1]\tTest-rmse:3.70075\n",
      "[2]\tTest-rmse:3.66402\n",
      "[3]\tTest-rmse:3.64829\n",
      "[4]\tTest-rmse:3.6375\n",
      "[5]\tTest-rmse:3.63642\n",
      "[6]\tTest-rmse:3.63471\n",
      "[7]\tTest-rmse:3.63187\n",
      "[8]\tTest-rmse:3.62936\n",
      "[9]\tTest-rmse:3.62917\n",
      "[10]\tTest-rmse:3.6284\n",
      "[11]\tTest-rmse:3.62863\n",
      "[12]\tTest-rmse:3.62878\n",
      "[13]\tTest-rmse:3.62948\n",
      "[14]\tTest-rmse:3.62905\n",
      "[15]\tTest-rmse:3.6278\n",
      "[16]\tTest-rmse:3.62833\n",
      "[17]\tTest-rmse:3.62794\n",
      "[18]\tTest-rmse:3.62907\n",
      "[19]\tTest-rmse:3.62998\n",
      "[20]\tTest-rmse:3.62851\n",
      "[21]\tTest-rmse:3.62894\n",
      "[22]\tTest-rmse:3.62766\n",
      "[23]\tTest-rmse:3.62784\n",
      "[24]\tTest-rmse:3.63194\n",
      "[25]\tTest-rmse:3.63176\n",
      "[26]\tTest-rmse:3.63209\n",
      "[27]\tTest-rmse:3.63164\n",
      "[28]\tTest-rmse:3.63269\n",
      "[29]\tTest-rmse:3.63195\n",
      "[30]\tTest-rmse:3.63247\n",
      "[31]\tTest-rmse:3.63355\n",
      "[32]\tTest-rmse:3.6345\n",
      "Stopping. Best iteration:\n",
      "[22]\tTest-rmse:3.62766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# No cross-validation; single thread\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 3.63 with 23 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RMSE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.824151</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>3.845768</td>\n",
       "      <td>0.038694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.743784</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>3.783899</td>\n",
       "      <td>0.038037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.694852</td>\n",
       "      <td>0.009345</td>\n",
       "      <td>3.752170</td>\n",
       "      <td>0.037258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.659074</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>3.733303</td>\n",
       "      <td>0.036987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.633878</td>\n",
       "      <td>0.010136</td>\n",
       "      <td>3.724616</td>\n",
       "      <td>0.037409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.614419</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>3.719167</td>\n",
       "      <td>0.036381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.597450</td>\n",
       "      <td>0.009206</td>\n",
       "      <td>3.716252</td>\n",
       "      <td>0.037217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.582534</td>\n",
       "      <td>0.007625</td>\n",
       "      <td>3.715262</td>\n",
       "      <td>0.037262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.569413</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>3.714629</td>\n",
       "      <td>0.036281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.558153</td>\n",
       "      <td>0.007342</td>\n",
       "      <td>3.713058</td>\n",
       "      <td>0.036246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.548822</td>\n",
       "      <td>0.007774</td>\n",
       "      <td>3.712457</td>\n",
       "      <td>0.036325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0          3.824151        0.009559        3.845768       0.038694\n",
       "1          3.743784        0.009105        3.783899       0.038037\n",
       "2          3.694852        0.009345        3.752170       0.037258\n",
       "3          3.659074        0.008756        3.733303       0.036987\n",
       "4          3.633878        0.010136        3.724616       0.037409\n",
       "5          3.614419        0.011418        3.719167       0.036381\n",
       "6          3.597450        0.009206        3.716252       0.037217\n",
       "7          3.582534        0.007625        3.715262       0.037262\n",
       "8          3.569413        0.008879        3.714629       0.036281\n",
       "9          3.558153        0.007342        3.713058       0.036246\n",
       "10         3.548822        0.007774        3.712457       0.036325"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation to find \n",
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=0,\n",
    "    nfold=5,\n",
    "    metrics={'rmse'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results # current parameters\n",
    "\n",
    "# Rows: number of boosting trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7124574000000004"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best RMSE score\n",
    "cv_results['test-rmse-mean'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune max_depth and min_child_weight\n",
    "# - Tune in conjunction to manage bias-variance tradeoff\n",
    "\n",
    "# max_depth: constrain tree complexity; guard against overfitting\n",
    "# min_child_weight: minimum number of samples to create a new node in the tree (smaller = more likely to overfit)\n",
    "\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(4,12)\n",
    "    for min_child_weight in range(10,50,10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=4, min_child_weight=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brad\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRMSE 3.7025404 for 39 rounds\n",
      "CV with max_depth=4, min_child_weight=20\n",
      "\tRMSE 3.6983932000000004 for 32 rounds\n",
      "CV with max_depth=4, min_child_weight=30\n",
      "\tRMSE 3.7013074 for 37 rounds\n",
      "CV with max_depth=4, min_child_weight=40\n",
      "\tRMSE 3.698410199999999 for 52 rounds\n",
      "CV with max_depth=5, min_child_weight=10\n",
      "\tRMSE 3.7046080000000003 for 19 rounds\n",
      "CV with max_depth=5, min_child_weight=20\n",
      "\tRMSE 3.7037670000000005 for 18 rounds\n",
      "CV with max_depth=5, min_child_weight=30\n",
      "\tRMSE 3.698261 for 33 rounds\n",
      "CV with max_depth=5, min_child_weight=40\n",
      "\tRMSE 3.698092 for 20 rounds\n",
      "CV with max_depth=6, min_child_weight=10\n",
      "\tRMSE 3.7108552 for 13 rounds\n",
      "CV with max_depth=6, min_child_weight=20\n",
      "\tRMSE 3.7049390000000004 for 15 rounds\n",
      "CV with max_depth=6, min_child_weight=30\n",
      "\tRMSE 3.7062508000000003 for 11 rounds\n",
      "CV with max_depth=6, min_child_weight=40\n",
      "\tRMSE 3.7001102 for 19 rounds\n",
      "CV with max_depth=7, min_child_weight=10\n",
      "\tRMSE 3.7163618 for 9 rounds\n",
      "CV with max_depth=7, min_child_weight=20\n",
      "\tRMSE 3.7135614000000006 for 9 rounds\n",
      "CV with max_depth=7, min_child_weight=30\n",
      "\tRMSE 3.7163116 for 9 rounds\n",
      "CV with max_depth=7, min_child_weight=40\n",
      "\tRMSE 3.709595 for 11 rounds\n",
      "CV with max_depth=8, min_child_weight=10\n",
      "\tRMSE 3.7345544000000004 for 8 rounds\n",
      "CV with max_depth=8, min_child_weight=20\n",
      "\tRMSE 3.7217816 for 8 rounds\n",
      "CV with max_depth=8, min_child_weight=30\n",
      "\tRMSE 3.7225304 for 8 rounds\n",
      "CV with max_depth=8, min_child_weight=40\n",
      "\tRMSE 3.7149398 for 7 rounds\n",
      "CV with max_depth=9, min_child_weight=10\n",
      "\tRMSE 3.7408342000000006 for 5 rounds\n",
      "CV with max_depth=9, min_child_weight=20\n",
      "\tRMSE 3.7320465999999994 for 5 rounds\n",
      "CV with max_depth=9, min_child_weight=30\n",
      "\tRMSE 3.731648 for 5 rounds\n",
      "CV with max_depth=9, min_child_weight=40\n",
      "\tRMSE 3.7246943999999997 for 5 rounds\n",
      "CV with max_depth=10, min_child_weight=10\n",
      "\tRMSE 3.7556107999999995 for 4 rounds\n",
      "CV with max_depth=10, min_child_weight=20\n",
      "\tRMSE 3.7471075999999996 for 4 rounds\n",
      "CV with max_depth=10, min_child_weight=30\n",
      "\tRMSE 3.7422908 for 5 rounds\n",
      "CV with max_depth=10, min_child_weight=40\n",
      "\tRMSE 3.7317810000000002 for 6 rounds\n",
      "CV with max_depth=11, min_child_weight=10\n",
      "\tRMSE 3.7689732 for 3 rounds\n",
      "CV with max_depth=11, min_child_weight=20\n",
      "\tRMSE 3.7509512000000003 for 4 rounds\n",
      "CV with max_depth=11, min_child_weight=30\n",
      "\tRMSE 3.7488784 for 4 rounds\n",
      "CV with max_depth=11, min_child_weight=40\n",
      "\tRMSE 3.7390786 for 4 rounds\n",
      "Best params: 5, 40, RMSE: 3.698092\n"
     ]
    }
   ],
   "source": [
    "# Define initial best params and MAE\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=0,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "        \n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params['max_depth'] = 4\n",
    "#params['min_child_weight'] = 36\n",
    "\n",
    "# new\n",
    "params['max_depth'] = 5\n",
    "params['min_child_weight'] = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    #for subsample in [i/10. for i in range(7,11)]\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(3,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brad\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRMSE 3.698092 for 20 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tRMSE 3.6965822000000004 for 23 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tRMSE 3.6994266000000002 for 25 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tRMSE 3.7002021999999997 for 23 rounds\n",
      "CV with subsample=1.0, colsample=0.6\n",
      "\tRMSE 3.6997838 for 29 rounds\n",
      "CV with subsample=1.0, colsample=0.5\n",
      "\tRMSE 3.6987906 for 28 rounds\n",
      "CV with subsample=1.0, colsample=0.4\n",
      "\tRMSE 3.6991278000000003 for 26 rounds\n",
      "CV with subsample=1.0, colsample=0.3\n",
      "\tRMSE 3.7015826000000005 for 39 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tRMSE 3.697797 for 22 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tRMSE 3.7007144 for 27 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tRMSE 3.7003408 for 28 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tRMSE 3.7003708000000004 for 17 rounds\n",
      "CV with subsample=0.9, colsample=0.6\n",
      "\tRMSE 3.7000066000000005 for 29 rounds\n",
      "CV with subsample=0.9, colsample=0.5\n",
      "\tRMSE 3.6987544 for 20 rounds\n",
      "CV with subsample=0.9, colsample=0.4\n",
      "\tRMSE 3.6974794 for 22 rounds\n",
      "CV with subsample=0.9, colsample=0.3\n",
      "\tRMSE 3.7007676000000003 for 30 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tRMSE 3.701399 for 16 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tRMSE 3.7041138000000005 for 14 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tRMSE 3.702839 for 19 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tRMSE 3.6985146 for 19 rounds\n",
      "CV with subsample=0.8, colsample=0.6\n",
      "\tRMSE 3.6997512 for 20 rounds\n",
      "CV with subsample=0.8, colsample=0.5\n",
      "\tRMSE 3.6959676000000004 for 28 rounds\n",
      "CV with subsample=0.8, colsample=0.4\n",
      "\tRMSE 3.7006259999999997 for 20 rounds\n",
      "CV with subsample=0.8, colsample=0.3\n",
      "\tRMSE 3.7012538 for 30 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tRMSE 3.7075646 for 11 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tRMSE 3.7056945999999997 for 24 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tRMSE 3.7081922 for 26 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tRMSE 3.704216 for 28 rounds\n",
      "CV with subsample=0.7, colsample=0.6\n",
      "\tRMSE 3.7035472 for 24 rounds\n",
      "CV with subsample=0.7, colsample=0.5\n",
      "\tRMSE 3.7013108000000003 for 20 rounds\n",
      "CV with subsample=0.7, colsample=0.4\n",
      "\tRMSE 3.7001006 for 20 rounds\n",
      "CV with subsample=0.7, colsample=0.3\n",
      "\tRMSE 3.7017374000000003 for 22 rounds\n",
      "Best params: 0.8, 0.5, RMSEE: 3.6959676000000004\n"
     ]
    }
   ],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=0,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, RMSEE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params['subsample'] = 1.0\n",
    "#params['colsample_bytree'] = 0.6\n",
    "\n",
    "# new\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "CV with eta=0.3\n",
      "Wall time: 22.4 s\n",
      "\tRMSE 3.6959676000000004 for 28 rounds\n",
      "\n",
      "CV with eta=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brad\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.7 s\n",
      "\tRMSE 3.6949778 for 36 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "Wall time: 1min 9s\n",
      "\tRMSE 3.6887582 for 123 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "Wall time: 1min 34s\n",
      "\tRMSE 3.6867959999999997 for 172 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "Wall time: 8min 20s\n",
      "\tRMSE 3.6839033999999997 for 998 rounds\n",
      "\n",
      "CV with eta=0.005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[0;32m    443\u001b[0m                            evaluation_result_list=None))\n\u001b[0;32m    444\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1110\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRMSE 3.6839033999999997 for 998 rounds\n",
      "\n",
      "Best params: 0.01, RMSE: 3.6839033999999997\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# This can take some timeâ€¦\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    \n",
    "    %time cv_results = xgb.cv(params,dtrain,num_boost_round=num_boost_round,seed=0,nfold=5,metrics=['rmse'],early_stopping_rounds=10)\n",
    "    \n",
    "    # Update best score\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\\n\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, RMSE: {}\".format(best_params, min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params['eta'] = .1\n",
    "\n",
    "params['eta'] = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:3.87139\n",
      "Will train until Test-rmse hasn't improved in 10 rounds.\n",
      "[1]\tTest-rmse:3.85024\n",
      "[2]\tTest-rmse:3.83121\n",
      "[3]\tTest-rmse:3.81382\n",
      "[4]\tTest-rmse:3.79818\n",
      "[5]\tTest-rmse:3.78465\n",
      "[6]\tTest-rmse:3.77148\n",
      "[7]\tTest-rmse:3.75926\n",
      "[8]\tTest-rmse:3.74824\n",
      "[9]\tTest-rmse:3.73835\n",
      "[10]\tTest-rmse:3.72907\n",
      "[11]\tTest-rmse:3.72103\n",
      "[12]\tTest-rmse:3.71281\n",
      "[13]\tTest-rmse:3.70554\n",
      "[14]\tTest-rmse:3.69887\n",
      "[15]\tTest-rmse:3.69329\n",
      "[16]\tTest-rmse:3.68799\n",
      "[17]\tTest-rmse:3.68289\n",
      "[18]\tTest-rmse:3.67814\n",
      "[19]\tTest-rmse:3.67359\n",
      "[20]\tTest-rmse:3.67001\n",
      "[21]\tTest-rmse:3.66628\n",
      "[22]\tTest-rmse:3.66297\n",
      "[23]\tTest-rmse:3.65964\n",
      "[24]\tTest-rmse:3.65635\n",
      "[25]\tTest-rmse:3.65383\n",
      "[26]\tTest-rmse:3.65117\n",
      "[27]\tTest-rmse:3.64926\n",
      "[28]\tTest-rmse:3.64711\n",
      "[29]\tTest-rmse:3.64532\n",
      "[30]\tTest-rmse:3.64371\n",
      "[31]\tTest-rmse:3.64181\n",
      "[32]\tTest-rmse:3.64004\n",
      "[33]\tTest-rmse:3.63876\n",
      "[34]\tTest-rmse:3.63722\n",
      "[35]\tTest-rmse:3.63612\n",
      "[36]\tTest-rmse:3.63512\n",
      "[37]\tTest-rmse:3.63426\n",
      "[38]\tTest-rmse:3.63317\n",
      "[39]\tTest-rmse:3.63204\n",
      "[40]\tTest-rmse:3.63101\n",
      "[41]\tTest-rmse:3.62985\n",
      "[42]\tTest-rmse:3.629\n",
      "[43]\tTest-rmse:3.62797\n",
      "[44]\tTest-rmse:3.6274\n",
      "[45]\tTest-rmse:3.62691\n",
      "[46]\tTest-rmse:3.626\n",
      "[47]\tTest-rmse:3.62502\n",
      "[48]\tTest-rmse:3.62446\n",
      "[49]\tTest-rmse:3.62425\n",
      "[50]\tTest-rmse:3.62358\n",
      "[51]\tTest-rmse:3.6233\n",
      "[52]\tTest-rmse:3.62282\n",
      "[53]\tTest-rmse:3.62228\n",
      "[54]\tTest-rmse:3.62219\n",
      "[55]\tTest-rmse:3.62153\n",
      "[56]\tTest-rmse:3.62128\n",
      "[57]\tTest-rmse:3.6209\n",
      "[58]\tTest-rmse:3.62012\n",
      "[59]\tTest-rmse:3.61976\n",
      "[60]\tTest-rmse:3.61928\n",
      "[61]\tTest-rmse:3.61888\n",
      "[62]\tTest-rmse:3.61837\n",
      "[63]\tTest-rmse:3.61819\n",
      "[64]\tTest-rmse:3.618\n",
      "[65]\tTest-rmse:3.61765\n",
      "[66]\tTest-rmse:3.61744\n",
      "[67]\tTest-rmse:3.61713\n",
      "[68]\tTest-rmse:3.61676\n",
      "[69]\tTest-rmse:3.61654\n",
      "[70]\tTest-rmse:3.61641\n",
      "[71]\tTest-rmse:3.61621\n",
      "[72]\tTest-rmse:3.61601\n",
      "[73]\tTest-rmse:3.6158\n",
      "[74]\tTest-rmse:3.61544\n",
      "[75]\tTest-rmse:3.61524\n",
      "[76]\tTest-rmse:3.61489\n",
      "[77]\tTest-rmse:3.61475\n",
      "[78]\tTest-rmse:3.61434\n",
      "[79]\tTest-rmse:3.61418\n",
      "[80]\tTest-rmse:3.61379\n",
      "[81]\tTest-rmse:3.61364\n",
      "[82]\tTest-rmse:3.61296\n",
      "[83]\tTest-rmse:3.61286\n",
      "[84]\tTest-rmse:3.61273\n",
      "[85]\tTest-rmse:3.61236\n",
      "[86]\tTest-rmse:3.61205\n",
      "[87]\tTest-rmse:3.61155\n",
      "[88]\tTest-rmse:3.61112\n",
      "[89]\tTest-rmse:3.61101\n",
      "[90]\tTest-rmse:3.61083\n",
      "[91]\tTest-rmse:3.61075\n",
      "[92]\tTest-rmse:3.61078\n",
      "[93]\tTest-rmse:3.61054\n",
      "[94]\tTest-rmse:3.6105\n",
      "[95]\tTest-rmse:3.61055\n",
      "[96]\tTest-rmse:3.61007\n",
      "[97]\tTest-rmse:3.60968\n",
      "[98]\tTest-rmse:3.60961\n",
      "[99]\tTest-rmse:3.60939\n",
      "[100]\tTest-rmse:3.60932\n",
      "[101]\tTest-rmse:3.60937\n",
      "[102]\tTest-rmse:3.60903\n",
      "[103]\tTest-rmse:3.60904\n",
      "[104]\tTest-rmse:3.60902\n",
      "[105]\tTest-rmse:3.60894\n",
      "[106]\tTest-rmse:3.60896\n",
      "[107]\tTest-rmse:3.6088\n",
      "[108]\tTest-rmse:3.60862\n",
      "[109]\tTest-rmse:3.60867\n",
      "[110]\tTest-rmse:3.6083\n",
      "[111]\tTest-rmse:3.60823\n",
      "[112]\tTest-rmse:3.60782\n",
      "[113]\tTest-rmse:3.60781\n",
      "[114]\tTest-rmse:3.60742\n",
      "[115]\tTest-rmse:3.60734\n",
      "[116]\tTest-rmse:3.60733\n",
      "[117]\tTest-rmse:3.60727\n",
      "[118]\tTest-rmse:3.60721\n",
      "[119]\tTest-rmse:3.60715\n",
      "[120]\tTest-rmse:3.60682\n",
      "[121]\tTest-rmse:3.60688\n",
      "[122]\tTest-rmse:3.6065\n",
      "[123]\tTest-rmse:3.6065\n",
      "[124]\tTest-rmse:3.60655\n",
      "[125]\tTest-rmse:3.60658\n",
      "[126]\tTest-rmse:3.60654\n",
      "[127]\tTest-rmse:3.60649\n",
      "[128]\tTest-rmse:3.6064\n",
      "[129]\tTest-rmse:3.60604\n",
      "[130]\tTest-rmse:3.60579\n",
      "[131]\tTest-rmse:3.6056\n",
      "[132]\tTest-rmse:3.6052\n",
      "[133]\tTest-rmse:3.60472\n",
      "[134]\tTest-rmse:3.6045\n",
      "[135]\tTest-rmse:3.60446\n",
      "[136]\tTest-rmse:3.60438\n",
      "[137]\tTest-rmse:3.60391\n",
      "[138]\tTest-rmse:3.60387\n",
      "[139]\tTest-rmse:3.60371\n",
      "[140]\tTest-rmse:3.60367\n",
      "[141]\tTest-rmse:3.60375\n",
      "[142]\tTest-rmse:3.60367\n",
      "[143]\tTest-rmse:3.60363\n",
      "[144]\tTest-rmse:3.60351\n",
      "[145]\tTest-rmse:3.60328\n",
      "[146]\tTest-rmse:3.60323\n",
      "[147]\tTest-rmse:3.60318\n",
      "[148]\tTest-rmse:3.60296\n",
      "[149]\tTest-rmse:3.60311\n",
      "[150]\tTest-rmse:3.60305\n",
      "[151]\tTest-rmse:3.60304\n",
      "[152]\tTest-rmse:3.60297\n",
      "[153]\tTest-rmse:3.603\n",
      "[154]\tTest-rmse:3.60303\n",
      "[155]\tTest-rmse:3.60283\n",
      "[156]\tTest-rmse:3.60291\n",
      "[157]\tTest-rmse:3.60306\n",
      "[158]\tTest-rmse:3.60291\n",
      "[159]\tTest-rmse:3.60287\n",
      "[160]\tTest-rmse:3.60267\n",
      "[161]\tTest-rmse:3.60242\n",
      "[162]\tTest-rmse:3.60237\n",
      "[163]\tTest-rmse:3.60227\n",
      "[164]\tTest-rmse:3.60209\n",
      "[165]\tTest-rmse:3.6017\n",
      "[166]\tTest-rmse:3.60162\n",
      "[167]\tTest-rmse:3.60153\n",
      "[168]\tTest-rmse:3.60149\n",
      "[169]\tTest-rmse:3.60146\n",
      "[170]\tTest-rmse:3.6014\n",
      "[171]\tTest-rmse:3.60127\n",
      "[172]\tTest-rmse:3.60111\n",
      "[173]\tTest-rmse:3.60095\n",
      "[174]\tTest-rmse:3.60091\n",
      "[175]\tTest-rmse:3.60076\n",
      "[176]\tTest-rmse:3.60083\n",
      "[177]\tTest-rmse:3.60077\n",
      "[178]\tTest-rmse:3.60084\n",
      "[179]\tTest-rmse:3.60067\n",
      "[180]\tTest-rmse:3.60063\n",
      "[181]\tTest-rmse:3.60064\n",
      "[182]\tTest-rmse:3.60066\n",
      "[183]\tTest-rmse:3.60069\n",
      "[184]\tTest-rmse:3.60065\n",
      "[185]\tTest-rmse:3.60069\n",
      "[186]\tTest-rmse:3.60074\n",
      "[187]\tTest-rmse:3.60073\n",
      "[188]\tTest-rmse:3.60076\n",
      "[189]\tTest-rmse:3.60065\n",
      "[190]\tTest-rmse:3.60067\n",
      "Stopping. Best iteration:\n",
      "[180]\tTest-rmse:3.60063\n",
      "\n",
      "Best RMSE: 3.60 in 181 rounds\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "print(\"Best RMSE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_iteration + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:3.87139\n",
      "[1]\tTest-rmse:3.85024\n",
      "[2]\tTest-rmse:3.83121\n",
      "[3]\tTest-rmse:3.81382\n",
      "[4]\tTest-rmse:3.79818\n",
      "[5]\tTest-rmse:3.78465\n",
      "[6]\tTest-rmse:3.77148\n",
      "[7]\tTest-rmse:3.75926\n",
      "[8]\tTest-rmse:3.74824\n",
      "[9]\tTest-rmse:3.73835\n",
      "[10]\tTest-rmse:3.72907\n",
      "[11]\tTest-rmse:3.72103\n",
      "[12]\tTest-rmse:3.71281\n",
      "[13]\tTest-rmse:3.70554\n",
      "[14]\tTest-rmse:3.69887\n",
      "[15]\tTest-rmse:3.69329\n",
      "[16]\tTest-rmse:3.68799\n",
      "[17]\tTest-rmse:3.68289\n",
      "[18]\tTest-rmse:3.67814\n",
      "[19]\tTest-rmse:3.67359\n",
      "[20]\tTest-rmse:3.67001\n",
      "[21]\tTest-rmse:3.66628\n",
      "[22]\tTest-rmse:3.66297\n",
      "[23]\tTest-rmse:3.65964\n",
      "[24]\tTest-rmse:3.65635\n",
      "[25]\tTest-rmse:3.65383\n",
      "[26]\tTest-rmse:3.65117\n",
      "[27]\tTest-rmse:3.64926\n",
      "[28]\tTest-rmse:3.64711\n",
      "[29]\tTest-rmse:3.64532\n",
      "[30]\tTest-rmse:3.64371\n",
      "[31]\tTest-rmse:3.64181\n",
      "[32]\tTest-rmse:3.64004\n",
      "[33]\tTest-rmse:3.63876\n",
      "[34]\tTest-rmse:3.63722\n",
      "[35]\tTest-rmse:3.63612\n",
      "[36]\tTest-rmse:3.63512\n",
      "[37]\tTest-rmse:3.63426\n",
      "[38]\tTest-rmse:3.63317\n",
      "[39]\tTest-rmse:3.63204\n",
      "[40]\tTest-rmse:3.63101\n",
      "[41]\tTest-rmse:3.62985\n",
      "[42]\tTest-rmse:3.629\n",
      "[43]\tTest-rmse:3.62797\n",
      "[44]\tTest-rmse:3.6274\n",
      "[45]\tTest-rmse:3.62691\n",
      "[46]\tTest-rmse:3.626\n",
      "[47]\tTest-rmse:3.62502\n",
      "[48]\tTest-rmse:3.62446\n",
      "[49]\tTest-rmse:3.62425\n",
      "[50]\tTest-rmse:3.62358\n",
      "[51]\tTest-rmse:3.6233\n",
      "[52]\tTest-rmse:3.62282\n",
      "[53]\tTest-rmse:3.62228\n",
      "[54]\tTest-rmse:3.62219\n",
      "[55]\tTest-rmse:3.62153\n",
      "[56]\tTest-rmse:3.62128\n",
      "[57]\tTest-rmse:3.6209\n",
      "[58]\tTest-rmse:3.62012\n",
      "[59]\tTest-rmse:3.61976\n",
      "[60]\tTest-rmse:3.61928\n",
      "[61]\tTest-rmse:3.61888\n",
      "[62]\tTest-rmse:3.61837\n",
      "[63]\tTest-rmse:3.61819\n",
      "[64]\tTest-rmse:3.618\n",
      "[65]\tTest-rmse:3.61765\n",
      "[66]\tTest-rmse:3.61744\n",
      "[67]\tTest-rmse:3.61713\n",
      "[68]\tTest-rmse:3.61676\n",
      "[69]\tTest-rmse:3.61654\n",
      "[70]\tTest-rmse:3.61641\n",
      "[71]\tTest-rmse:3.61621\n",
      "[72]\tTest-rmse:3.61601\n",
      "[73]\tTest-rmse:3.6158\n",
      "[74]\tTest-rmse:3.61544\n",
      "[75]\tTest-rmse:3.61524\n",
      "[76]\tTest-rmse:3.61489\n",
      "[77]\tTest-rmse:3.61475\n",
      "[78]\tTest-rmse:3.61434\n",
      "[79]\tTest-rmse:3.61418\n",
      "[80]\tTest-rmse:3.61379\n",
      "[81]\tTest-rmse:3.61364\n",
      "[82]\tTest-rmse:3.61296\n",
      "[83]\tTest-rmse:3.61286\n",
      "[84]\tTest-rmse:3.61273\n",
      "[85]\tTest-rmse:3.61236\n",
      "[86]\tTest-rmse:3.61205\n",
      "[87]\tTest-rmse:3.61155\n",
      "[88]\tTest-rmse:3.61112\n",
      "[89]\tTest-rmse:3.61101\n",
      "[90]\tTest-rmse:3.61083\n",
      "[91]\tTest-rmse:3.61075\n",
      "[92]\tTest-rmse:3.61078\n",
      "[93]\tTest-rmse:3.61054\n",
      "[94]\tTest-rmse:3.6105\n",
      "[95]\tTest-rmse:3.61055\n",
      "[96]\tTest-rmse:3.61007\n",
      "[97]\tTest-rmse:3.60968\n",
      "[98]\tTest-rmse:3.60961\n",
      "[99]\tTest-rmse:3.60939\n",
      "[100]\tTest-rmse:3.60932\n",
      "[101]\tTest-rmse:3.60937\n",
      "[102]\tTest-rmse:3.60903\n",
      "[103]\tTest-rmse:3.60904\n",
      "[104]\tTest-rmse:3.60902\n",
      "[105]\tTest-rmse:3.60894\n",
      "[106]\tTest-rmse:3.60896\n",
      "[107]\tTest-rmse:3.6088\n",
      "[108]\tTest-rmse:3.60862\n",
      "[109]\tTest-rmse:3.60867\n",
      "[110]\tTest-rmse:3.6083\n",
      "[111]\tTest-rmse:3.60823\n",
      "[112]\tTest-rmse:3.60782\n",
      "[113]\tTest-rmse:3.60781\n",
      "[114]\tTest-rmse:3.60742\n",
      "[115]\tTest-rmse:3.60734\n",
      "[116]\tTest-rmse:3.60733\n",
      "[117]\tTest-rmse:3.60727\n",
      "[118]\tTest-rmse:3.60721\n",
      "[119]\tTest-rmse:3.60715\n",
      "[120]\tTest-rmse:3.60682\n",
      "[121]\tTest-rmse:3.60688\n",
      "[122]\tTest-rmse:3.6065\n",
      "[123]\tTest-rmse:3.6065\n",
      "[124]\tTest-rmse:3.60655\n",
      "[125]\tTest-rmse:3.60658\n",
      "[126]\tTest-rmse:3.60654\n",
      "[127]\tTest-rmse:3.60649\n",
      "[128]\tTest-rmse:3.6064\n",
      "[129]\tTest-rmse:3.60604\n",
      "[130]\tTest-rmse:3.60579\n",
      "[131]\tTest-rmse:3.6056\n",
      "[132]\tTest-rmse:3.6052\n",
      "[133]\tTest-rmse:3.60472\n",
      "[134]\tTest-rmse:3.6045\n",
      "[135]\tTest-rmse:3.60446\n",
      "[136]\tTest-rmse:3.60438\n",
      "[137]\tTest-rmse:3.60391\n",
      "[138]\tTest-rmse:3.60387\n",
      "[139]\tTest-rmse:3.60371\n",
      "[140]\tTest-rmse:3.60367\n",
      "[141]\tTest-rmse:3.60375\n",
      "[142]\tTest-rmse:3.60367\n",
      "[143]\tTest-rmse:3.60363\n",
      "[144]\tTest-rmse:3.60351\n",
      "[145]\tTest-rmse:3.60328\n",
      "[146]\tTest-rmse:3.60323\n",
      "[147]\tTest-rmse:3.60318\n",
      "[148]\tTest-rmse:3.60296\n",
      "[149]\tTest-rmse:3.60311\n",
      "[150]\tTest-rmse:3.60305\n",
      "[151]\tTest-rmse:3.60304\n",
      "[152]\tTest-rmse:3.60297\n",
      "[153]\tTest-rmse:3.603\n",
      "[154]\tTest-rmse:3.60303\n",
      "[155]\tTest-rmse:3.60283\n",
      "[156]\tTest-rmse:3.60291\n",
      "[157]\tTest-rmse:3.60306\n",
      "[158]\tTest-rmse:3.60291\n",
      "[159]\tTest-rmse:3.60287\n",
      "[160]\tTest-rmse:3.60267\n",
      "[161]\tTest-rmse:3.60242\n",
      "[162]\tTest-rmse:3.60237\n",
      "[163]\tTest-rmse:3.60227\n",
      "[164]\tTest-rmse:3.60209\n",
      "[165]\tTest-rmse:3.6017\n",
      "[166]\tTest-rmse:3.60162\n",
      "[167]\tTest-rmse:3.60153\n",
      "[168]\tTest-rmse:3.60149\n",
      "[169]\tTest-rmse:3.60146\n",
      "[170]\tTest-rmse:3.6014\n",
      "[171]\tTest-rmse:3.60127\n",
      "[172]\tTest-rmse:3.60111\n",
      "[173]\tTest-rmse:3.60095\n",
      "[174]\tTest-rmse:3.60091\n",
      "[175]\tTest-rmse:3.60076\n",
      "[176]\tTest-rmse:3.60083\n",
      "[177]\tTest-rmse:3.60077\n",
      "[178]\tTest-rmse:3.60084\n",
      "[179]\tTest-rmse:3.60067\n",
      "[180]\tTest-rmse:3.60063\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model used 181 decision trees\n"
     ]
    }
   ],
   "source": [
    "# Number of Trees (best model)\n",
    "print('Best model used {} decision trees'.format(num_boost_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees: 181\n",
      "\n",
      "Final parameters\n",
      "\n",
      "{'eval_metric': 'rmse', 'max_depth': 5, 'min_child_weight': 40, 'eta': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.5, 'objective': 'reg:linear'}\n",
      "\n",
      "RMSE of predictions on test set: 3.600634349650864\n"
     ]
    }
   ],
   "source": [
    "print('Trees: {}'.format(num_boost_round))\n",
    "print()\n",
    "print('Final parameters\\n')\n",
    "print(params)\n",
    "print()\n",
    "print('RMSE of predictions on test set: {}'.format(mean_squared_error(y_test, best_model.predict(dtest))**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "best_model.save_model(\"eng_train_new_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.600634349595675\n",
      "12.96456771948827\n"
     ]
    }
   ],
   "source": [
    "# Loading model for later use\n",
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(\"eng_train_new_model.model\")\n",
    "\n",
    "# Made predictions with loaded model\n",
    "loaded_model.predict(dtest)\n",
    "\n",
    "print(mean_squared_error(y_test, loaded_model.predict(dtest))**0.5)\n",
    "print(mean_squared_error(y_test, loaded_model.predict(dtest)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
